{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Za≈Çadowanie danych i bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_account_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings</th>\n",
       "      <th>present_employment</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal</th>\n",
       "      <th>other_debtors</th>\n",
       "      <th>present_residence</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>other_installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>dependents</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>customer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A11</td>\n",
       "      <td>6</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>A65</td>\n",
       "      <td>A75</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>67.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A12</td>\n",
       "      <td>48</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A92</td>\n",
       "      <td>A101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>22.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A14</td>\n",
       "      <td>12</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>2096.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A121</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A11</td>\n",
       "      <td>42</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>7882.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A74</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A122</td>\n",
       "      <td>45.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A11</td>\n",
       "      <td>24</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>A61</td>\n",
       "      <td>A73</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A93</td>\n",
       "      <td>A101</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A124</td>\n",
       "      <td>53.0</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>2.0</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_account_status  duration credit_history purpose  credit_amount  \\\n",
       "0                     A11         6            A34     A43         1169.0   \n",
       "1                     A12        48            A32     A43         5951.0   \n",
       "2                     A14        12            A34     A46         2096.0   \n",
       "3                     A11        42            A32     A42         7882.0   \n",
       "4                     A11        24            A33     A40         4870.0   \n",
       "\n",
       "  savings present_employment  installment_rate personal other_debtors  \\\n",
       "0     A65                A75               4.0      A93          A101   \n",
       "1     A61                A73               2.0      A92          A101   \n",
       "2     A61                A74               2.0      A93          A101   \n",
       "3     A61                A74               2.0      A93          A103   \n",
       "4     A61                A73               3.0      A93          A101   \n",
       "\n",
       "   present_residence property   age other_installment_plans housing  \\\n",
       "0                4.0     A121  67.0                    A143    A152   \n",
       "1                2.0     A121  22.0                    A143    A152   \n",
       "2                3.0     A121  49.0                    A143    A152   \n",
       "3                4.0     A122  45.0                    A143    A153   \n",
       "4                4.0     A124  53.0                    A143    A153   \n",
       "\n",
       "   existing_credits   job  dependents telephone foreign_worker  customer_type  \n",
       "0               2.0  A173           1      A192           A201              1  \n",
       "1               1.0  A173           1      A191           A201              2  \n",
       "2               1.0  A172           2      A191           A201              1  \n",
       "3               1.0  A173           2      A191           A201              1  \n",
       "4               2.0  A173           2      A191           A201              2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import preprocessing \n",
    "from sklearn import metrics\n",
    "import random\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Grain setting guarantees the reproductibility of results\n",
    "np.random.seed(123)\n",
    "# Showing all columns in DataFrame preview\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Loading data\n",
    "data = pd.read_csv('german_credit_data_dataset.csv')\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test sets split\n",
    "# 80% of observations belong to the training set the rest to the test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data.drop('customer_type', axis=1), data['customer_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost for James-Stein Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataframe\n",
    "dtrain = pd.concat([X_train,Y_train], axis=1)\n",
    "\n",
    "#test dataframe\n",
    "dtest = pd.concat([X_test,Y_test], axis=1)\n",
    "\n",
    "target = \"customer_type\"\n",
    "\n",
    "# Selection of columns to be encoded\n",
    "cols = data.select_dtypes(include = 'object').columns.values \n",
    "\n",
    "# Building the encoder\n",
    "encoder = ce.JamesSteinEncoder(cols = cols)\n",
    "\n",
    "#encoding train dataframe\n",
    "dtrain = encoder.fit_transform(X = dtrain, y = dtrain[target])\n",
    "#changing target labels to binary labels for binary xboost algorithm 1 -> 1 (good customer), 2 -> 0 (bad customer) \n",
    "dtrain[target] = dtrain[target].map({1:1, 2:0})\n",
    "\n",
    "#encoding test dataframe\n",
    "dtest = encoder.transform(X = dtest)\n",
    "#changing target labels to binary labels for binary xboost algorithm 1 -> 1 (good customer), 2 -> 0 (bad customer) \n",
    "dtest[target] = dtest[target].map({1:1, 2:0})\n",
    "\n",
    "predictors = [x for x in dtrain.columns if x not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which finds the optimum number of trees (n_estimators parameter) using cv function of xgboost\n",
    "# for given learning_rate and changes the alg parameter accrodingly\n",
    "def modelfit(alg, dtrain, predictors, cv_folds = 5, early_stopping_rounds = 50):\n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round = alg.get_params()['n_estimators'],\n",
    "                      nfold=cv_folds, metrics='auc', early_stopping_rounds = early_stopping_rounds)\n",
    "    alg.set_params(n_estimators = cvresult.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our default calssifier, whose parameters will be tuned in grid_search_cv\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators = 1000,\n",
    " max_depth = 5,\n",
    " min_child_weight = 1,\n",
    " gamma = 0,\n",
    " subsample = 0.8,\n",
    " colsample_bytree = 0.8,\n",
    " objective = 'binary:logistic',\n",
    " nthread = 4,\n",
    " scale_pos_weight = 1,\n",
    " seed = 27)\n",
    "\n",
    "# Firstly let's assume fixed learning_rate = 0.1 and find optimum n_estiamtors parameter value for it\n",
    "modelfit(xgb1, dtrain, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 8, 'classifier__min_child_weight': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Pipeline([\n",
    "  ('classifier', xgb1)\n",
    "])\n",
    "\n",
    "# Parametred which will be tested in grid_search_cv\n",
    "parameters = {\n",
    "    'classifier__max_depth': range (2, 10, 1),\n",
    "    'classifier__min_child_weight': range(1,10,1)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(model1, param_grid = parameters, cv = 5)\n",
    "gsearch1.fit(dtrain[predictors], dtrain[target])\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace our estimator with the best one\n",
    "xgb2 = gsearch1.best_estimator_.steps[0][1]\n",
    "# find the optimum n_estimators parameter\n",
    "modelfit(xgb2, dtrain, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__gamma': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = gsearch1.best_estimator_\n",
    "\n",
    "# Parametred which will be tested in grid_search_cv\n",
    "parameters = {\n",
    "    'classifier__gamma': [i/10.0 for i in range(0,5)],\n",
    "}\n",
    "\n",
    "gsearch2 = GridSearchCV(model2, param_grid = parameters, cv = 5)\n",
    "gsearch2.fit(dtrain[predictors], dtrain[target])\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace our estimator with the best one\n",
    "xgb3 = gsearch2.best_estimator_.steps[0][1]\n",
    "# find the optimum n_estimators parameter\n",
    "modelfit(xgb3, dtrain, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__colsample_bytree': 0.85, 'classifier__subsample': 0.55}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = gsearch2.best_estimator_\n",
    "\n",
    "# Parametred which will be tested in grid_search_cv\n",
    "parameters = {\n",
    "    'classifier__subsample':[i/100.0 for i in range(50,100,5)],\n",
    "    'classifier__colsample_bytree':[i/100.0 for i in range(50,100,5)]\n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(model3, param_grid = parameters, cv = 5)\n",
    "gsearch3.fit(dtrain[predictors], dtrain[target])\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Tune learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace our estimator with the best one and lower learning rate to get more trees \n",
    "xgb4 = gsearch3.best_estimator_.steps[0][1]\n",
    "xgb4.set_params(learning_rate = 0.01)\n",
    "# We also have to increase n_estimators so that number of trees wouldn't limit learning rate\n",
    "xgb4.set_params(n_estimators = 5000)\n",
    "# After all just find the optimum n_estimators parameter for changed learning_rate\n",
    "modelfit(xgb3, dtrain, predictors)\n",
    "#final model\n",
    "model4 = Pipeline([\n",
    "  ('classifier', xgb4)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Final James-Stein encoding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(dtest[predictors], dtest[target])\n",
    "\n",
    "predict_class1 = model4.predict(dtest[predictors])\n",
    "predict_proba1 = model4.predict_proba(dtest[predictors])[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost for One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataframe\n",
    "dtrain = pd.concat([X_train,Y_train], axis=1)\n",
    "\n",
    "#test dataframe\n",
    "dtest = pd.concat([X_test,Y_test], axis=1)\n",
    "\n",
    "# Building the encoder\n",
    "onehot_encoder = ce.OneHotEncoder(data, cols = cols)\n",
    "\n",
    "#encoding train dataframe\n",
    "dtrain = onehot_encoder.fit_transform(X = dtrain, y = dtrain[\"customer_type\"])\n",
    "#changing target labels to binary labels for binary xboost algorithm 1 -> 1 (good customer), 2 -> 0 (bad customer) \n",
    "dtrain[\"customer_type\"] = dtrain[\"customer_type\"].map({1:1, 2:0})\n",
    "\n",
    "#encoding test dataframe\n",
    "dtest = onehot_encoder.transform(X = dtest)\n",
    "#changing target labels to binary labels for binary xboost algorithm 1 -> 1 (good customer), 2 -> 0 (bad customer) \n",
    "dtest[\"customer_type\"] = dtest[\"customer_type\"].map({1:1, 2:0})\n",
    "\n",
    "predictors = [x for x in dtrain.columns if x not in [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our default calssifier, whose parameters will be tuned in grid_search_cv\n",
    "xgb1 = xgb.XGBClassifier(\n",
    " learning_rate = 0.1,\n",
    " n_estimators = 1000,\n",
    " max_depth = 5,\n",
    " min_child_weight = 1,\n",
    " gamma = 0,\n",
    " subsample = 0.8,\n",
    " colsample_bytree = 0.8,\n",
    " objective = 'binary:logistic',\n",
    " nthread = 4,\n",
    " scale_pos_weight = 1,\n",
    " seed = 27)\n",
    "\n",
    "# Firstly let's assume fixed learning_rate = 0.1 and find optimum n_estiamtors\n",
    "# parameter value for it\n",
    "modelfit(xgb1, dtrain, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 2, 'classifier__min_child_weight': 4}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Pipeline([\n",
    "  ('classifier', xgb1)\n",
    "])\n",
    "\n",
    "# Parametred which will be tested in grid_search_cv\n",
    "parameters = {\n",
    "    'classifier__max_depth': range (2, 10, 1),\n",
    "    'classifier__min_child_weight': range(1,10,1)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(model1, param_grid = parameters, cv = 5)\n",
    "gsearch1.fit(dtrain[predictors], dtrain[target])\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace our estimator with the best one\n",
    "xgb2 = gsearch1.best_estimator_.steps[0][1]\n",
    "# find the optimum n_estimators parameter\n",
    "modelfit(xgb2, dtrain, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tune gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__gamma': 0.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = gsearch1.best_estimator_\n",
    "\n",
    "# Parametred which will be tested in grid_search_cv\n",
    "parameters = {\n",
    "    'classifier__gamma': [i/10.0 for i in range(0,5)],\n",
    "}\n",
    "\n",
    "gsearch2 = GridSearchCV(model2, param_grid = parameters, cv = 5)\n",
    "gsearch2.fit(dtrain[predictors], dtrain[target])\n",
    "gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace our estimator with the best one\n",
    "xgb3 = gsearch2.best_estimator_.steps[0][1]\n",
    "# find the optimum n_estimators parameter\n",
    "modelfit(xgb3, dtrain, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Tune subsample and colsample_bytree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__colsample_bytree': 0.65, 'classifier__subsample': 0.85}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = gsearch2.best_estimator_\n",
    "\n",
    "# Parametred which will be tested in grid_search_cv\n",
    "parameters = {\n",
    "    'classifier__subsample':[i/100.0 for i in range(50,100,5)],\n",
    "    'classifier__colsample_bytree':[i/100.0 for i in range(50,100,5)]\n",
    "}\n",
    "\n",
    "gsearch3 = GridSearchCV(model3, param_grid = parameters, cv = 5)\n",
    "gsearch3.fit(dtrain[predictors], dtrain[target])\n",
    "gsearch3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Tune learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace our estimator with the best one and lower learning rate to get more trees \n",
    "xgb4 = gsearch3.best_estimator_.steps[0][1]\n",
    "xgb4.set_params(learning_rate = 0.01)\n",
    "# We also have to increase n_estimators so that number of trees wouldn't limit learning rate\n",
    "xgb4.set_params(n_estimators = 5000)\n",
    "# After all just find the optimum n_estimators parameter for changed learning_rate\n",
    "modelfit(xgb3, dtrain, predictors)\n",
    "#final model\n",
    "model4 = Pipeline([\n",
    "  ('classifier', xgb4)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(dtest[predictors], dtest[target])\n",
    "\n",
    "predict_class2 = model4.predict(dtest[predictors])\n",
    "predict_proba2 = model4.predict_proba(dtest[predictors])[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoder</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James-Stein Encoding</td>\n",
       "      <td>0.972488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Hot Encoding</td>\n",
       "      <td>0.996008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Encoder       AUC\n",
       "0  James-Stein Encoding  0.972488\n",
       "1      One Hot Encoding  0.996008"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = Y_test.map({1:1, 2:0})\n",
    "\n",
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(Y_test, predict_proba1) # false & true positive rates\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(Y_test, predict_proba2) # false & true positive rates\n",
    "\n",
    "pd.DataFrame({\"Encoder\" : [\"James-Stein Encoding\", \"One Hot Encoding\"],\n",
    "             \"AUC\": [metrics.auc(fpr1, tpr1), metrics.auc(fpr2, tpr2)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoder</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Stein Encoding</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One Hot Encoding</td>\n",
       "      <td>0.969738</td>\n",
       "      <td>0.988095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Encoder  Precision    Recall\n",
       "0  James Stein Encoding   0.900491  0.952381\n",
       "1      One Hot Encoding   0.969738  0.988095"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Encoder\" : [\"James Stein Encoding\", \"One Hot Encoding\"],\n",
    "             \"Precision\": [precision_score(Y_test, predict_class1, average='macro'), precision_score(Y_test, predict_class2, average='macro')],\n",
    "             \"Recall\": [recall_score(Y_test, predict_class1), recall_score(Y_test, predict_class2)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROCR curve\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr1, tpr1, label='James Stein Encoding')\n",
    "plt.plot(fpr2, tpr2, label='One Hot Encoding')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
